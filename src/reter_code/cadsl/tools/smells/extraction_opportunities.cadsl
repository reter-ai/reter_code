# extraction_opportunities - Find code clusters suitable for common function extraction
#
# PURPOSE: Detect code fragments that could be extracted into shared utility functions.
# If several methods contain similar code blocks, that code can be extracted to reduce
# redundancy and improve maintainability.
#
# HOW IT WORKS:
# - Method bodies are chunked (30 lines, 10 overlap) and indexed by embeddings
# - K-means clustering groups chunks with similar code patterns
# - Clusters with DIFFERENT method names but SIMILAR bodies indicate extraction opportunities
#
# RECOMMENDED USAGE:
# - Use high cluster count (800-1200) for finer granularity
# - Use file_filter=".py" to focus on one language at a time
# - Manually review results - expect ~25% true positive rate
# - Look for LEXICAL similarity (same code text), not just semantic similarity
#
# Example TRUE POSITIVE:
#   3 files with: `for ext in EXTENSIONS: for f in root.rglob(f'*{ext}'): ...`
#   → Extract to: `scan_code_files(root, extensions, exclude_func)`
#
# Example FALSE POSITIVE:
#   Multiple `to_dict()` methods returning different fields
#   → This is interface pattern, not duplicated code

detector extraction_opportunities(category="extraction-review", severity="medium") {
    """
    Find clusters of similar code that could be extracted into shared functions.

    This tool detects CODE EXTRACTION OPPORTUNITIES - places where similar code
    fragments exist across multiple methods and could be consolidated into a
    shared utility function, reducing redundancy.

    Method bodies are chunked (30 lines with 10-line overlap) and clustered by
    embedding similarity. Clusters with DIFFERENT method names but SIMILAR code
    bodies indicate potential extraction targets.

    Parameters:
        n_clusters: Number of K-means clusters (default: 100, recommended: 800-1200)
        min_cluster_size: Minimum members to report a cluster (default: 3)
        min_unique_files: Minimum unique files in cluster (default: 2)
        include_tests: Include test files (default: false)
        include_visitors: Include ANTLR visitor methods (default: false)
        file_filter: Filter by file extension, e.g. ".py" for Python only
        limit: Maximum clusters to report (default: 30)
        dry_run: Preview without creating tasks (default: true)

    Recommended usage:
        n_clusters=1200, file_filter=".py", limit=30

    Expected results:
        ~25% true positive rate - manual review required to filter out:
        - Interface patterns (to_dict, _register_methods)
        - Layered architecture (same params through client→service→handler)
        - Coincidental structural similarity (common Python idioms)

    Output:
        Creates one task per cluster with detailed review guidance,
        ordered by cluster size (largest potential impact first).
    """

    param n_clusters: int = 800;
    param min_cluster_size: int = 3;
    param min_unique_files: int = 2;
    param include_tests: bool = false;
    param include_visitors: bool = false;
    param file_filter: str = "";  # e.g. ".py" for Python only, ".cpp" for C++ only
    param limit: int = 30;
    param dry_run: bool = true;

    # Use RAG K-means clustering - groups similar code by embeddings
    rag {
        clusters,
        n_clusters: {n_clusters},
        min_size: {min_cluster_size},
        exclude_same_file: false,
        exclude_same_class: true,
        entity_types: ["method", "function"]
    }
    # Filter clusters: keep only those with DIFFERENT method names
    # (indicating body similarity, not just name similarity)
    | python {
        VISITOR_PATTERNS = ["visit", "Visit", "enter", "exit", "Enter", "Exit"]
        TEST_PATTERNS = ["/test/", "_test.py", "test_", "/tests/", "conftest.py"]
        BOILERPLATE = {"get_category", "get_conditions", "get_name", "get_type",
                       "__init__", "__str__", "__repr__", "__hash__", "__eq__",
                       "setUp", "tearDown", "get_id", "register_to"}

        include_tests = ctx.params.get("include_tests", False) if ctx else False
        include_visitors = ctx.params.get("include_visitors", False) if ctx else False
        min_unique_files = int(ctx.params.get("min_unique_files", 2)) if ctx else 2
        file_filter = ctx.params.get("file_filter", "") if ctx else ""

        output = []
        for cluster in rows:
            members = cluster.get("details", [])
            if not members:
                continue

            # Filter members
            filtered_members = []
            unique_files = set()
            unique_names = set()

            for m in members:
                name = m.get("name", "")
                file_path = m.get("file", "")

                # Apply file filter (e.g. ".py" for Python only)
                if file_filter and not file_path.endswith(file_filter):
                    continue

                # Skip boilerplate
                if name in BOILERPLATE:
                    continue

                # Skip visitors unless requested
                if not include_visitors:
                    is_visitor = any(name.startswith(p) for p in VISITOR_PATTERNS)
                    if is_visitor:
                        continue

                # Skip tests unless requested
                if not include_tests:
                    is_test = any(p in file_path for p in TEST_PATTERNS)
                    if is_test:
                        continue

                filtered_members.append(m)
                unique_files.add(file_path.replace("\\", "/"))
                unique_names.add(name)

            # KEY FILTER: Only keep clusters with DIFFERENT method names
            # If all names are the same, it's likely interface pattern (FP)
            # If names differ, bodies are similar = extraction opportunity
            if len(unique_names) < 2:
                continue

            # Only keep clusters with enough unique files
            if len(unique_files) >= min_unique_files and len(filtered_members) >= 2:
                cluster["members"] = filtered_members
                cluster["unique_files"] = len(unique_files)
                cluster["unique_names"] = len(unique_names)
                cluster["member_count"] = len(filtered_members)
                output.append(cluster)

        result = output
    }
    # Sort by impact (more members = more extraction value)
    | order_by { -member_count, -unique_files }
    | limit { {limit} }
    # Build task description with all cluster members
    | python {
        output = []
        for cluster in rows:
            members = cluster.get("details", [])
            if not members:
                continue

            # Get representative name (most common method name in cluster)
            name_counts = {}
            for m in members:
                n = m.get("name", "unknown")
                name_counts[n] = name_counts.get(n, 0) + 1
            representative_name = max(name_counts, key=name_counts.get)

            # Build member list for description
            member_lines = []
            for i, m in enumerate(members[:10]):  # Limit to 10 in description
                file_path = m.get("file", "")
                line = m.get("line", 0)
                name = m.get("name", "")
                class_name = m.get("class_name", "")
                qual = f"{class_name}.{name}" if class_name else name
                member_lines.append(f"{i+1}. `{file_path}:{line}` - `{qual}`")

            if len(members) > 10:
                member_lines.append(f"   ... and {len(members) - 10} more")

            members_text = chr(10).join(member_lines)

            # Collect unique names for task title
            unique_names = list(set(m.get("name", "") for m in members))[:3]
            names_str = ", ".join(unique_names)
            if len(set(m.get("name", "") for m in members)) > 3:
                names_str += ", ..."

            output.append({
                "cluster_id": cluster.get("cluster_id", 0),
                "member_count": len(members),
                "unique_files": cluster.get("unique_files", 0),
                "unique_names": cluster.get("unique_names", 0),
                "avg_similarity": round(1.0 - cluster.get("avg_distance", 0) / 2.0, 3),
                "representative_name": representative_name,
                "names_summary": names_str,
                "members_text": members_text,
                "first_file": members[0].get("file", "") if members else "",
                "priority": "high" if len(members) >= 5 else "medium"
            })
        result = output
    }
    | create_task {
        name: "[extract] {member_count}x similar: {names_summary}",
        category: "extraction-review",
        priority: {priority},
        description: "**Extraction Opportunity** - {member_count} similar implementations across {unique_files} files\n\n**Cluster**: {unique_names} different method names with similar bodies\n**Avg Similarity**: {avg_similarity}\n\n---\n\n**Locations to review:**\n{members_text}\n\n---\n\n## What We're Looking For\n\nCode fragments (loops, conditionals, sequences of statements) that are **nearly identical** across multiple methods and could be extracted into a shared utility function.\n\n**TRUE POSITIVE example:** Similar loops iterating over extensions and scanning files with rglob patterns across multiple methods - these could be extracted into a shared utility function like `scan_code_files(root, extensions, exclude_func)`.\n\n---\n\n## How to Review\n\n1. **Read the actual code** at each location listed above\n2. **Compare lexically** - is the code TEXT nearly identical (not just semantically similar)?\n3. **Check extractability** - could this become a shared function in a utils module?\n\n---\n\n## Common FALSE POSITIVES\n\n- **FP-INTERFACE**: Same method signature across classes (e.g., `to_dict`, `_register_methods`) - Template/Strategy pattern, not duplication\n- **FP-LAYERS**: Same parameters passed through architectural layers (client → service → handler) - proper layering, not duplication\n- **FP-STRUCTURAL**: Similar Python idioms (dict returns, list comprehensions, try/except) - coincidental structure, different logic\n- **FP-TRIVIAL**: Very short methods (1-3 lines) that happen to be similar\n\n---\n\n## Classification\n\n- **TP-EXTRACT**: Real duplication - create shared utility function\n- **TP-PARAMETERIZE**: Similar with small variations - extract with parameters\n- **PARTIAL-TP**: Some extractable fragments within larger different methods\n- **FP-INTERFACE/LAYERS/STRUCTURAL**: Not actual duplication",
        affects: first_file,
        dry_run: {dry_run}
    }
    | emit { tasks }
}
